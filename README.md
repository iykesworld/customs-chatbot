ðŸ‡³ðŸ‡¬ NCS Internal Inquiry Assistant (RAG Chatbot)
Project Overview
This project is a sophisticated, internal knowledge base assistant designed for Nigeria Customs Service (NCS) officers. It utilizes Retrieval-Augmented Generation (RAG) principles to provide instant, grounded answers to complex regulatory questions by querying a curated knowledge base of official documents.

This application demonstrates proficiency in building modern, full-stack Agentic AI solutions that solve real-world enterprise efficiency challenges, significantly reducing the time officers spend searching through manuals for information on tariffs, prohibited items, and legal provisions.

Key Features
Retrieval-Augmented Generation (RAG): The model is prevented from hallucinating by grounding all answers in the provided NCS knowledge base text.

Source Citation: Every answer generated by the AI is accompanied by collapsible source citations, allowing the user to verify the exact text retrieved from the official documents.

Full-Stack Architecture: A robust and scalable separation of concerns using Python (FastAPI/LangChain) for the AI logic and Next.js/React for the professional user interface.

Responsive UI: A modern, professional user interface built with Next.js and Tailwind CSS, designed for clarity and ease of use on desktop and mobile devices.

Architecture & Technology Stack
The project is structured into two main components:

Component

Technology

Description

Backend (RAG Engine)

Python, FastAPI, LangChain, OpenAI

Handles document chunking, embedding generation, vector database indexing (FAISS), and the core RAG query logic.

Frontend (UI)

Next.js, React, TypeScript, Tailwind CSS

Provides the user interface, manages chat state, and communicates with the FastAPI endpoint via REST.

Knowledge Base

Plain Text (Mock NCS Docs)

The single source of truth used to ground the LLM's responses.

Setup and Installation
Follow these steps to get the application running locally.

Prerequisites
OpenAI API Key: Ensure you have your OPENAI_API_KEY.

Node.js & npm/yarn: Required for the Next.js frontend.

Python (3.9+): Required for the FastAPI backend.

1. Backend Setup
Navigate to the backend directory:

cd backend

Create and activate the virtual environment (using uv):

uv venv
.\.venv\Scripts\activate  # On Windows PowerShell
# source .venv/bin/activate # On Linux/macOS

Install Python dependencies:

uv pip install -r requirements.txt

Configure Environment: Create a file named .env in the backend/ directory and add your API key:

OPENAI_API_KEY="YOUR_API_KEY_HERE"

Run the Backend Server:

uvicorn app.main:app --reload --port 8000

The server should start on http://127.0.0.1:8000. You will see a confirmation that the RAG chain has been initialized.

2. Frontend Setup
Navigate to the frontend directory:

cd ../frontend

Install Node dependencies:

npm install
# or yarn install

Run the Frontend Development Server:

npm run dev

The frontend should be accessible at http://localhost:3000.

How to Test
With both the backend (port 8000) and frontend (port 3000) running, open your browser to the frontend and submit a query based on the mocked knowledge base content (see backend/data/customs_knowledge_base.txt).

Example Queries:

Tariff: "What is the total duty/levy on an imported used car?"

Prohibited Items: "List all the items that are prohibited from importation."

NCS Act: "How long do imported goods have before they are deemed overtime cargo according to the NCS Act 2023?"